{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard_logger==0.1.0 in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from tensorboard_logger==0.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from tensorboard_logger==0.1.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.5/dist-packages (from tensorboard_logger==0.1.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.5/dist-packages (from tensorboard_logger==0.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.5/dist-packages (from tensorboard_logger==0.1.0)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.5/dist-packages (from pillow>=4.1.1->tensorboard_logger==0.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf->tensorboard_logger==0.1.0)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorboard_logger==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tensorboard_logger import Logger\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from settings.paths import FILTERED_MS_CELEB_IMAGES_DIR, \\\n",
    "                           SRGAN_MSE_LOSS_LOGS_DIR, \\\n",
    "                           SRGAN_VGG_LOSS_LOGS_DIR, \\\n",
    "                           SRGAN_LIGHT_CNN_LOSS_LOGS_DIR, \\\n",
    "                           SRGAN_MSE_LOSS_WEIGHTS_DIR, \\\n",
    "                           SRGAN_VGG_LOSS_WEIGHTS_DIR, \\\n",
    "                           SRGAN_LIGHT_CNN_LOSS_WEIGHTS_DIR\n",
    "from utils import maybe_mkdir, remove_if_exists, get_last_file\n",
    "                           \n",
    "from src.srgan import Generator, Discriminator, FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6, 7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MSCeleb(ImageFolder):\n",
    "    def __init__(self, root):\n",
    "        super().__init__(root)\n",
    "        \n",
    "        self._to_tensor = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self._downscale = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(32, 0),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, _ = super().__getitem__(index)\n",
    "        \n",
    "        image_hr = self._to_tensor(image)\n",
    "        image_lr = self._downscale(image_hr)\n",
    "        \n",
    "        return image_hr, image_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = MSCeleb(FILTERED_MS_CELEB_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_loader = DataLoader(\n",
    "    dataset, batch_size=16, shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRGANManager:\n",
    "    def __init__(self,\n",
    "                 dataset_loader,\n",
    "                 n_resblocks=16, n_upsample=2,\n",
    "                 generator_lr=0.0001, discriminator_lr=0.0001,\n",
    "                 batch_size=16,\n",
    "                 cuda=True):\n",
    "        self._batch_size = batch_size\n",
    "        \n",
    "        self._generator = Generator(n_resblocks, n_upsample)\n",
    "        self._discriminator = Discriminator()\n",
    "        \n",
    "        self._content_criterion = nn.MSELoss()\n",
    "        self._adversarial_criterion = nn.BCELoss()\n",
    "        self._ones_const = Variable(torch.ones(BATCH_SIZE, 1))\n",
    "        \n",
    "        self._cuda = cuda\n",
    "        if self._cuda is True:\n",
    "            self._generator = nn.DataParallel(self._generator).cuda()\n",
    "            self._discriminator = nn.DataParallel(self._discriminator).cuda()\n",
    "            self._content_criterion = self._content_criterion.cuda()\n",
    "            self._adversarial_criterion = self._adversarial_criterion.cuda()\n",
    "            self._ones_const = self._ones_const.cuda()\n",
    "        \n",
    "        self._optim_generator = optim.Adam(\n",
    "            self._generator.parameters(), lr=generator_lr\n",
    "        )\n",
    "        self._optim_discriminator = optim.Adam(\n",
    "            self._discriminator.parameters(), lr=discriminator_lr\n",
    "        )\n",
    "        \n",
    "        self._dataset_loader = dataset_loader\n",
    "        \n",
    "    def load_generator_weights(self, path):\n",
    "        self._generator.load_state_dict(torch.load(path))\n",
    "        \n",
    "    def load_discriminator_weights(self, path):\n",
    "        self._discriminator.load_state_dict(torch.load(path))\n",
    "\n",
    "    def train_mse_only(self,\n",
    "                       log_dir=SRGAN_MSE_LOSS_LOGS_DIR,\n",
    "                       epoch_count=30,\n",
    "                       generator_weights_dir=SRGAN_MSE_LOSS_WEIGHTS_DIR,\n",
    "                       save_frequency=15000,\n",
    "                       values_log_frequency=300,\n",
    "                       images_log_frequency=3000,\n",
    "                       start_log=100,\n",
    "                       train_type='careful'):\n",
    "        self._train(\n",
    "            log_dir=log_dir,\n",
    "            epoch_count=epoch_count,\n",
    "            train_function=self._mse_only_train_function,\n",
    "            generator_weights_dir=generator_weights_dir,\n",
    "            save_frequency=save_frequency,\n",
    "            values_log_frequency=values_log_frequency,\n",
    "            images_log_frequency=images_log_frequency,\n",
    "            start_log=start_log,\n",
    "            train_type=train_type\n",
    "        )\n",
    "            \n",
    "        \n",
    "    def _mse_only_train_function(self, high_res_real, high_res_fake):\n",
    "        self._generator.zero_grad()\n",
    "\n",
    "        generator_content_loss = self._content_criterion(\n",
    "            high_res_fake, high_res_real,\n",
    "        )\n",
    "\n",
    "        generator_content_loss.backward()\n",
    "        self._optim_generator.step()\n",
    "        \n",
    "        return {\n",
    "            'generator_mse_loss': generator_content_loss,\n",
    "        }\n",
    "        \n",
    "    def _train(self,\n",
    "               log_dir,\n",
    "               epoch_count,\n",
    "               train_function,\n",
    "               generator_weights_dir,\n",
    "               save_frequency=15000,\n",
    "               values_log_frequency=300,\n",
    "               images_log_frequency=3000,\n",
    "               start_log=100,\n",
    "               train_type='careful',\n",
    "               discriminator_weights_dir=None):\n",
    "        \n",
    "        try:\n",
    "            step_num = self._prepare_train_type(\n",
    "                train_type, log_dir,\n",
    "                generator_weights_dir, discriminator_weights_dir\n",
    "            )\n",
    "\n",
    "            logger = Logger(log_dir)\n",
    "\n",
    "            for epoch_number in range(epoch_count):\n",
    "                print('Epoch: {}'.format(epoch_number))\n",
    "                for image_hr, image_lr in tqdm(self._dataset_loader, total=len(self._dataset_loader)):\n",
    "                    high_res_real = Variable(image_hr)\n",
    "                    low_res = Variable(image_lr)\n",
    "                    high_res_fake = self._generator(low_res)\n",
    "                    if self._cuda is True:\n",
    "                        high_res_real = high_res_real.cuda()\n",
    "                        high_res_fake = high_res_fake.cuda()\n",
    "\n",
    "                    values_dict = train_function(high_res_real, high_res_fake)\n",
    "\n",
    "                    if step_num >= start_log:\n",
    "                        if step_num % values_log_frequency == 0:\n",
    "                            for key, value in values_dict.items():\n",
    "                                logger.log_value(\n",
    "                                    key,\n",
    "                                    value,\n",
    "                                    step_num\n",
    "                                )\n",
    "\n",
    "                        if step_num % images_log_frequency == 0:\n",
    "                            logger.log_images(\n",
    "                                'real_images',\n",
    "                                high_res_real.data.cpu()[:1],\n",
    "                                step_num\n",
    "                            )\n",
    "\n",
    "                            logger.log_images(\n",
    "                                'lr_images',\n",
    "                                low_res.data.cpu()[:1],\n",
    "                                step_num\n",
    "                            )\n",
    "\n",
    "                            logger.log_images(\n",
    "                                'fake_images',\n",
    "                                high_res_fake.data.cpu()[:1],\n",
    "                                step_num\n",
    "                            )\n",
    "\n",
    "                    if step_num % save_frequency == 0 and step_num != 0:\n",
    "                        self._save_all(step_num, generator_weights_dir, discriminator_weights_dir)\n",
    "\n",
    "                    step_num += 1\n",
    "\n",
    "            self._save_all(step_num, generator_weights_dir, discriminator_weights_dir)\n",
    "        except KeyboardInterrupt:\n",
    "            self._save_all(step_num, generator_weights_dir, discriminator_weights_dir)\n",
    "        \n",
    "    def _save_all(self, step_num, generator_weights_dir, discriminator_weights_dir=None):\n",
    "        torch.save(\n",
    "            self._generator.state_dict(), self._make_weight_path(generator_weights_dir, step_num)\n",
    "        )\n",
    "        \n",
    "        if discriminator_weights_dir is not None:\n",
    "            torch.save(\n",
    "                self._discriminator.state_dict(), self._make_weight_path(discriminator_weights_dir, step_num)\n",
    "            )\n",
    "        \n",
    "    def _prepare_train_type(self, train_type, log_dir,\n",
    "                            generator_weights_dir, discriminator_weights_dir=None):\n",
    "        step = 0\n",
    "        \n",
    "        if train_type is 'careful':\n",
    "            print(log_dir)\n",
    "            if os.path.exists(log_dir) or os.path.exists(generator_weights_dir) or \\\n",
    "               (discriminator_weights_dir is not None and os.path.exists(discriminator_weights_dir)):\n",
    "                raise AssertionError('There are previous train files')\n",
    "        elif train_type is 'clean':\n",
    "            print(\n",
    "                'Clean all train data for (Y/N):\\nlog_dir: {}\\ngenerator_weights_dir: {}\\ndiscriminator_weights_dir: {}'.format(\n",
    "                    log_dir,\n",
    "                    generator_weights_dir,\n",
    "                    discriminator_weights_dir,\n",
    "                )\n",
    "            )\n",
    "            answer = input()\n",
    "            if answer == 'Y':\n",
    "                remove_if_exists(log_dir)\n",
    "                remove_if_exists(generator_weights_dir)\n",
    "                if discriminator_weights_dir is not None:\n",
    "                    remove_if_exists(discriminator_weights_dir)\n",
    "            else:\n",
    "                raise Exception('Bad answer')\n",
    "        elif train_type is 'continue':\n",
    "            try:\n",
    "                filename = get_last_file(generator_weights_dir)\n",
    "                self.load_generator_weights(os.path.join(generator_weights_dir, filename))\n",
    "\n",
    "                if discriminator_weights_dir is not None:\n",
    "                    filename = get_last_file(discriminator_weights_dir)\n",
    "                    self.load_discriminator_weights(os.path.join(discriminator_weights_dir, filename))\n",
    "                \n",
    "                step = int(os.path.splitext(filename)[0])\n",
    "            except Exception:\n",
    "                raise Exception('Nothing to load')\n",
    "        else:\n",
    "            raise ValueError('No such train type')\n",
    "            \n",
    "        pathlib.Path(generator_weights_dir).mkdir(parents=True, exist_ok=True)\n",
    "        if discriminator_weights_dir is not None:\n",
    "            pathlib.Path(discriminator_weights_dir).mkdir(parents=True, exist_ok=True)\n",
    "        pathlib.Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        return step\n",
    "        \n",
    "    def _make_weight_path(self, folder, step):\n",
    "        return os.path.join(folder, '{:010d}.pth'.format(step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srgan_manager = SRGANManager(dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srgan_manager.train_mse_only(epoch_count=30, train_type='clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
